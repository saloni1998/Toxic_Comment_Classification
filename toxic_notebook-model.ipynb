{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder='/home/saloni/Machine-learning/Toxic Comment Classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_txt_and_tar(folder,filename):\n",
    "    texts=[]\n",
    "    targets=[]\n",
    "    data=pd.read_csv(os.path.join(folder,filename))\n",
    "    for i in range(len(data)):\n",
    "        texts.append(data['comment_text'][i])\n",
    "        targets.append(np.array([float(x) for x in data.iloc[i][2:]]))\n",
    "    return texts,targets\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts,target=get_txt_and_tar(folder,'train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 159571)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts),len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 200\n",
    "VALIDATION_SPLIT = 0.05\n",
    "def get_datasets(texts,targets,tokenizer=None):\n",
    "    if tokenizer is None:\n",
    "        tokenizer=Tokenizer()\n",
    "        tokenizer.fit_on_texts(texts)\n",
    "    sequences=tokenizer.texts_to_sequences(texts)\n",
    "    word_index=tokenizer.word_index\n",
    "    data=pad_sequences(sequences,maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    #indices=np.arange(data.shape[0])\n",
    "    #np.random.shuffle(indices)\n",
    "    #data=data[indices]\n",
    "    #targets=targets[indices]\n",
    "    val_size=int(VALIDATION_SPLIT*data.shape[0])\n",
    "    x_train=data[:-val_size]\n",
    "    y_train=targets[:-val_size]\n",
    "    x_val=data[-val_size:]\n",
    "    y_val=targets[-val_size:]\n",
    "    \n",
    "    return tokenizer,word_index,x_train,y_train,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer, word_index, x_train, y_train, x_val, y_val = get_datasets(texts, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_glove_model():\n",
    "    WORD2VEC_FOLDER=\"/home/saloni/Machine-learning/Toxic Comment Classification\"\n",
    "    word2vec = KeyedVectors.load_word2vec_format(\n",
    "        os.path.join(WORD2VEC_FOLDER,\n",
    "                'glove.6B.100d.txt'),\n",
    "            binary=False)\n",
    "    return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2vec=load_glove_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec.wv[\"apple\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embedding_layer(word_index, gensim_model):\n",
    "    embedding_dim = 100\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if word in gensim_model.wv.vocab:\n",
    "            embedding_matrix[i] = gensim_model.wv[word]\n",
    "    embedding_layer = Embedding(len(word_index) + 1,\n",
    "            embedding_dim,\n",
    "            weights=[embedding_matrix],\n",
    "            input_length=MAX_SEQUENCE_LENGTH,\n",
    "            trainable=True)\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = get_embedding_layer(word_index, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_TARGET_CLASSES = 6\n",
    "def get_convnet_model(embedding_layer):\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(64, 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    preds = Dense(N_TARGET_CLASSES, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_convnet_model(embedding_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 100)          21033800  \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 196, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 35, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                14368     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 21,153,950\n",
      "Trainable params: 21,153,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151593 samples, validate on 7978 samples\n",
      "Epoch 1/2\n",
      "151593/151593 [==============================] - 1884s 12ms/step - loss: 0.0592 - acc: 0.9794 - val_loss: 0.0573 - val_acc: 0.9793\n",
      "Epoch 2/2\n",
      "151593/151593 [==============================] - 1747s 12ms/step - loss: 0.0504 - acc: 0.9815 - val_loss: 0.0556 - val_acc: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f212073eb70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='adagrad',\n",
    "        metrics=['accuracy'])\n",
    "model.fit(np.array(x_train),np.array( y_train), validation_data=(np.array(x_val),np.array( y_val)), epochs=2, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151593 samples, validate on 7978 samples\n",
      "Epoch 1/1\n",
      "151593/151593 [==============================] - 1855s 12ms/step - loss: 0.0431 - acc: 0.9836 - val_loss: 0.0567 - val_acc: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21207ad748>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x_train),np.array( y_train), validation_data=(np.array(x_val),np.array( y_val)), epochs=1, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"/home/saloni/Machine-learning/Toxic Comment Classification/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id=test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_text=test['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((151593, 200), (151593, 6))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train).shape,np.array(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sequences=tokenizer.texts_to_sequences(test_text)\n",
    "#word_index=tokenizer.word_index\n",
    "data_test=pad_sequences(test_sequences,maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 200)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(np.array(data_test),batch_size=64,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((153164, 6), 153164)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape,len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99190873,  0.32051873,  0.94017857,  0.08319982,  0.82984388,\n",
       "        0.18676686], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxic=[]\n",
    "severe_toxic=[]\n",
    "obscene=[]\n",
    "threat=[]\n",
    "insult=[]\n",
    "identity_hate=[]\n",
    "for i in range(len(predictions)):\n",
    "    toxic.append(predictions[i][0])\n",
    "    severe_toxic.append(predictions[i][1])\n",
    "    obscene.append(predictions[i][2])\n",
    "    threat.append(predictions[i][3])\n",
    "    insult.append(predictions[i][4])\n",
    "    identity_hate.append(predictions[i][5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"id\":test_id, \n",
    "                             \"toxic\":toxic,\n",
    "                             \"severe_toxic\":severe_toxic,\n",
    "                            \"obscene\":obscene, \n",
    "                             \"threat\":threat,\n",
    "                            \"insult\":insult,\n",
    "                            \"identity_hate\":identity_hate} )\n",
    "output.to_csv( \"../Toxic Comment Classification/output_toxic1(4ep).csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>score=0.9488</B> on LeaderBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
